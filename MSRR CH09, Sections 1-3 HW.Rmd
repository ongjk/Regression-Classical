---
title: "MSRR CH09, Sections 1-3 HW"
author: "Jefferson Ong"
date: 'Updated: `r format(Sys.time(), "%A, %B %d, %Y @ %X")`'
output: 
  html_document: 
    theme: yeti
    highlight: textmate
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, comment = "")
```

***

**Instructions**

Complete the following problems from _Mathematical Statistics with Resampling and R_. You can access the textbook datasets on our [Class Data Files](https://stat-jet-asu.github.io/Datasets/DatasetList.html) page or from the `R` package `resampledata`. The textbook examples use base `R`code for plotting, but you `ggplot2` for visualizations. You may use `table()` to make tables, but you should use `dplyr` for other summaries. Refer to the case studies in Chapter 1 to add informative titles and axis labels to your plots and to provide context for your answers.

Load the packages and datasets you need here.

```{r}
library(resampledata)
library(ggplot2)
library(dplyr)

library(moderndive)

```


***
#### Problem 9.6

Part (a) 

```{r}
str(Olympics2012)
summary(Olympics2012)
names(Olympics2012)
```


```{r}
Olympics2012 %>%
  summarize(corr = cor(Height, Weight))
```

Part (b)

Note: For "What do you observe?", comment on linearity, direction of trend, and outliers.

```{r}
ggplot(Olympics2012, aes(x = Height, y = Weight)) +
  geom_point() + geom_smooth(method = "lm", se = FALSE)
```


ANSWER: It is positively linear. Positive slope. 2 distinct outliers at the top. 

Part (c)

Hint: Use `filter()` with `Weight` to remove the outliers.

```{r}
OlympicWeight <- Olympics2012 %>%
  filter(Weight < 250)

ggplot(OlympicWeight, aes(x = Height, y = Weight)) +
  geom_point() + geom_smooth(method = "lm", se = FALSE)

OlympicWeight %>%
  summarize(corr = cor(Height, Weight))
```

ANSWER: Yes, it bought its correlation from .5 to .8. A huge increase. 


***
#### Problem 9.8

```{r}
str(RangersTwins2016)
summary(RangersTwins2016)
names(RangersTwins2016)
```


Part (a)

```{r}
ggplot(RangersTwins2016, aes(x = RBI, y = BA, color = Team)) +
  geom_point() + geom_smooth(method = "lm", se = FALSE)

RangersTwins2016 %>%
  summarize(corr = cor(RBI, BA))
```

Part (b)

```{r}
RangersTwins2016 %>%
  group_by(Team) %>%
  summarize(corr = cor(RBI, BA))
```

ANSWER: THe better team with higher win rate had a higher correlation between these things, while the worst team didn't. I would guess since the better team had a stronger correlation that their players had a good balance of RBI and BA compare to the worst team that might have bigger outliers. Looking more at the scatter plot, I'm not really seeing much of that, so eh. 


***
#### Problem 9.9

```{r}
str(NBA1617)
summary(NBA1617)
names(NBA1617)
```


Part (a)

```{r}
NBA1617 %>%
  summarize(corr = cor(PercFG, OffReb))
```

Part (b)

```{r}
NBAmeans <- NBA1617 %>%
  group_by(Team) %>%
  summarize(MeanpercFG = mean(PercFG), Meanoffreb = mean(OffReb))
```

Part (c)

```{r}
ggplot(NBAmeans, aes(x = MeanpercFG, y = Meanoffreb, color = Team)) +
  geom_point() + geom_smooth(method = "lm", se = FALSE)

NBAmeans %>%
  summarize(corr = cor(MeanpercFG, Meanoffreb))
```

Part (d)

ANSWER: Oddly high correlation, from .48 to .91. Not really sure how the math behind that works, that correlation base on rates or groups will have higher correlation. Its only 4 points on the scatter so, not really much to go on. 


***
#### Problem 9.16

Note: In (b), create a table of proportions as well as a table of counts to answer the question. In (c), also compute the upper fence for each group to show the upper cutoff for outliers.

```{r}
str(Beerwings)
summary(Beerwings)
names(Beerwings)
```


Part (a)

```{r}
ggplot(Beerwings, aes(x = Hotwings, y = Beer)) +
  geom_point() + geom_smooth(method = "lm", se = FALSE)

Beerwings %>%
  summarize(corr = cor(Hotwings, Beer), n())
```

Part (b)

```{r}
Beerwingsmodel <- lm(Beer ~ Hotwings, data = Beerwings)

BeerwingsSlope <- get_regression_table(Beerwingsmodel)

Beerwingsmodel
BeerwingsSlope
```

INTERPRETATION: If you tell me how many hotwings you will eat, I can predict how much beer you'd drink along with it. $\hat y = 3.040 + 1.941 * X$

Part (c)

```{r}

Beerwingsmodel <- lm(Beer ~ Hotwings, data = Beerwings)
ResidualLineBeer <- get_regression_points(Beerwingsmodel)


ResidualLineBeer %>%
  summarise(R_squared = 1 - var(residual) / var(Hotwings))
```

Well its negative, shows that it really isn't correlated? Not sure what to make of it. likely the residual points are quiet off with outliers. Not really sure about an upper fence when scatterplot shows it to be fairly spread out, I don't see any particular point that skews it greatly. 

Part (d) ADDED Perform a residual analysis like [MD 6.1.4](https://moderndive.com/6-regression.html#model1) and comment on the appropriateness of a straight-line model. 

```{r}
ResidualLineBeer <- get_regression_points(Beerwingsmodel)


ggplot(ResidualLineBeer, aes(x = Hotwings, y = residual)) +
  geom_point() +
  labs(x = "Hotwings", y = "residual", 
       title = "Residual line") +
   geom_hline(yintercept = 0, col = "blue", size = 1)
```

ANSWER:


***

```{r}
sessionInfo()
```
inting of the R code that generated the plot.
